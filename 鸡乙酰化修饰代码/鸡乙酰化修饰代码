#!/bin/bash
#############################################
# CUT&Tag Data Analysis Pipeline
# H3K27ac Histone Acetylation Profiling
# Complete Workflow from QC to Differential Analysis
#############################################

set -e
set -u
set -o pipefail

# ========== Color Output ==========
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

# ========== Configuration ==========
# !!! MODIFY THESE PATHS FOR YOUR SYSTEM !!!
WORK_DIR="/path/to/your/project"              # Main project directory
RAW_DATA="${WORK_DIR}/rawdata"                # Raw fastq files location
ANALYSIS_DIR="${WORK_DIR}/analysis_cuttag"    # Analysis output directory
REF_GENOME="/path/to/reference/genome.fa"     # Reference genome FASTA
REF_GTF="/path/to/annotation.gtf"             # Genome annotation GTF

# Computing Resources
THREADS=64                    # Total CPU cores available
ALIGNMENT_THREADS=64          # Threads for bowtie2
SORT_THREADS=32              # Threads for samtools sort
PEAK_THREADS=32              # Threads for deepTools

# Sample Information
SAMPLES=("Sample1" "Sample2" "Sample3" "Sample4" "Sample5" "Sample6")
# Note: First 3 samples are Control group, last 3 are Treatment group

# Analysis Parameters
GENOME_SIZE=1.05e9           # Effective genome size (chicken: 1.05e9, human: 2.7e9, mouse: 1.87e9)
QUALITY_THRESHOLD=20         # Phred quality score threshold
MIN_READ_LENGTH=20           # Minimum read length after trimming
MAPQ_FILTER=20              # Mapping quality filter

# ========== Logging Functions ==========
log_info() {
    echo -e "${GREEN}[INFO]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_warn() {
    echo -e "${YELLOW}[WARN]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $(date '+%Y-%m-%d %H:%M:%S') - $1"
}

log_step() {
    echo ""
    echo -e "${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}"
}

# ========== Check Software Dependencies ==========
check_software() {
    log_step "Checking Software Dependencies"
    
    local required=("fastqc" "multiqc" "trim_galore" "bowtie2" "samtools" "picard" "macs2" "bamCoverage")
    local missing=()
    
    for software in "${required[@]}"; do
        if command -v $software &> /dev/null; then
            log_info "✓ $software installed"
        else
            log_warn "✗ $software NOT installed"
            missing+=($software)
        fi
    done
    
    if [ ${#missing[@]} -gt 0 ]; then
        log_error "Missing software: ${missing[*]}"
        log_info "Install with: conda install -c bioconda ${missing[*]}"
        exit 1
    fi
}

# ========== Create Directory Structure ==========
create_directories() {
    log_step "Creating Directory Structure"
    
    mkdir -p ${ANALYSIS_DIR}/{01_fastqc/{raw,trimmed},02_trim,03_align/{bam,qc},04_peaks/{macs2,bigwig},05_diff_analysis/{standard,loose,strict,consensus},logs/{fastqc,trim,align,peaks,diff},scripts,reference}
    
    log_info "Directory structure created"
}

# ========== STEP 1: Quality Control ==========
step1_qc() {
    log_step "STEP 1: Quality Control (FastQC)"
    
    fastqc ${RAW_DATA}/*.fq.gz \
        -o ${ANALYSIS_DIR}/01_fastqc/raw \
        -t ${THREADS} \
        --nogroup \
        2>&1 | tee ${ANALYSIS_DIR}/logs/fastqc/step1_fastqc.log
    
    if command -v multiqc &> /dev/null; then
        multiqc ${ANALYSIS_DIR}/01_fastqc/raw \
            -o ${ANALYSIS_DIR}/01_fastqc/raw \
            -n raw_multiqc_report \
            --force
    fi
    
    log_info "✓ Step 1 completed"
}

# ========== STEP 2: Adapter Trimming ==========
step2_trim() {
    log_step "STEP 2: Adapter Trimming & Quality Filtering"
    
    for sample in "${SAMPLES[@]}"; do
        log_info "Processing ${sample}..."
        
        trim_galore \
            --paired \
            --quality ${QUALITY_THRESHOLD} \
            --phred33 \
            --stringency 5 \
            --length ${MIN_READ_LENGTH} \
            --cores 8 \
            --fastqc \
            --gzip \
            --output_dir ${ANALYSIS_DIR}/02_trim \
            ${RAW_DATA}/${sample}_R1.fq.gz \
            ${RAW_DATA}/${sample}_R2.fq.gz \
            2>&1 | tee ${ANALYSIS_DIR}/logs/trim/${sample}.log
    done
    
    # Move FastQC reports
    mv ${ANALYSIS_DIR}/02_trim/*_fastqc.* ${ANALYSIS_DIR}/01_fastqc/trimmed/ 2>/dev/null || true
    
    if command -v multiqc &> /dev/null; then
        multiqc ${ANALYSIS_DIR}/01_fastqc/trimmed \
            -o ${ANALYSIS_DIR}/01_fastqc/trimmed \
            -n trimmed_multiqc_report \
            --force
    fi
    
    log_info "✓ Step 2 completed"
}

# ========== STEP 3: Build Genome Index ==========
step3a_build_index() {
    log_step "STEP 3a: Building Bowtie2 Index"
    
    if [ ! -f "${ANALYSIS_DIR}/reference/genome.1.bt2" ]; then
        bowtie2-build \
            --threads ${THREADS} \
            ${REF_GENOME} \
            ${ANALYSIS_DIR}/reference/genome \
            2>&1 | tee ${ANALYSIS_DIR}/logs/align/bowtie2_build.log
        
        log_info "✓ Genome index built"
    else
        log_info "Genome index already exists, skipping..."
    fi
}

# ========== STEP 3b: Alignment & Filtering ==========
step3b_align() {
    log_step "STEP 3b: Alignment, Deduplication & Filtering"
    
    local INDEX="${ANALYSIS_DIR}/reference/genome"
    local TRIM_DIR="${ANALYSIS_DIR}/02_trim"
    local ALIGN_DIR="${ANALYSIS_DIR}/03_align"
    
    for sample in "${SAMPLES[@]}"; do
        log_info "Processing ${sample}..."
        
        # Skip if final BAM exists
        [ -f "${ALIGN_DIR}/bam/${sample}.final.bam" ] && log_info "${sample} already processed, skip" && continue
        
        # Alignment with Bowtie2
        bowtie2 -p ${ALIGNMENT_THREADS} \
            --very-sensitive \
            --phred33 \
            -I 10 -X 700 \
            --rg-id ${sample} \
            --rg "SM:${sample}" \
            --rg "PL:ILLUMINA" \
            -x ${INDEX} \
            -1 ${TRIM_DIR}/${sample}_R1_val_1.fq.gz \
            -2 ${TRIM_DIR}/${sample}_R2_val_2.fq.gz \
            2> ${ANALYSIS_DIR}/logs/align/${sample}.log | \
            samtools view -@ ${SORT_THREADS} -bS - | \
            samtools sort -@ ${SORT_THREADS} -o ${ALIGN_DIR}/bam/${sample}.sorted.bam
        
        # Index
        samtools index -@ 16 ${ALIGN_DIR}/bam/${sample}.sorted.bam
        
        # Remove duplicates with Picard
        picard -Xmx40g MarkDuplicates \
            I=${ALIGN_DIR}/bam/${sample}.sorted.bam \
            O=${ALIGN_DIR}/bam/${sample}.dedup.bam \
            M=${ALIGN_DIR}/qc/${sample}.dup.txt \
            REMOVE_DUPLICATES=true \
            ASSUME_SORTED=true \
            VALIDATION_STRINGENCY=LENIENT
        
        # Quality filter (MAPQ >= 20)
        samtools view -@ ${SORT_THREADS} -b -q ${MAPQ_FILTER} \
            ${ALIGN_DIR}/bam/${sample}.dedup.bam \
            -o ${ALIGN_DIR}/bam/${sample}.final.bam
        
        # Index final BAM
        samtools index -@ 16 ${ALIGN_DIR}/bam/${sample}.final.bam
        
        # Clean up intermediate files
        rm -f ${ALIGN_DIR}/bam/${sample}.sorted.bam* ${ALIGN_DIR}/bam/${sample}.dedup.bam*
        
        log_info "✓ ${sample} completed"
    done
    
    log_info "✓ Step 3 completed"
}

# ========== STEP 4: Peak Calling ==========
step4_peaks() {
    log_step "STEP 4: Peak Calling (MACS2) & BigWig Generation"
    
    # Peak calling with MACS2 (broad peaks for H3K27ac)
    for sample in "${SAMPLES[@]}"; do
        log_info "Calling peaks for ${sample}..."
        
        macs2 callpeak \
            -t ${ANALYSIS_DIR}/03_align/bam/${sample}.final.bam \
            -f BAMPE \
            -g ${GENOME_SIZE} \
            -n ${sample} \
            --outdir ${ANALYSIS_DIR}/04_peaks/macs2 \
            --broad \
            --broad-cutoff 0.05 \
            -q 0.05 \
            --keep-dup all \
            2>&1 | tee ${ANALYSIS_DIR}/logs/peaks/${sample}_macs2.log
    done
    
    # Generate BigWig for visualization
    for sample in "${SAMPLES[@]}"; do
        log_info "Generating BigWig for ${sample}..."
        
        bamCoverage \
            -b ${ANALYSIS_DIR}/03_align/bam/${sample}.final.bam \
            -o ${ANALYSIS_DIR}/04_peaks/bigwig/${sample}.bw \
            --binSize 10 \
            --normalizeUsing RPKM \
            --effectiveGenomeSize ${GENOME_SIZE%.*} \
            --numberOfProcessors ${PEAK_THREADS} \
            --extendReads \
            2>&1 | tee ${ANALYSIS_DIR}/logs/peaks/${sample}_bigwig.log
    done
    
    # Peak statistics
    echo "Peak Calling Summary:" > ${ANALYSIS_DIR}/04_peaks/peak_summary.txt
    for sample in "${SAMPLES[@]}"; do
        if [ -f "${ANALYSIS_DIR}/04_peaks/macs2/${sample}_peaks.broadPeak" ]; then
            count=$(wc -l < ${ANALYSIS_DIR}/04_peaks/macs2/${sample}_peaks.broadPeak)
            echo "${sample}: ${count} peaks" >> ${ANALYSIS_DIR}/04_peaks/peak_summary.txt
        fi
    done
    
    log_info "✓ Step 4 completed"
}

# ========== STEP 5: Differential Analysis (R Script) ==========
step5_diff_analysis() {
    log_step "STEP 5: Differential Peak Analysis (DESeq2)"
    
    cat > ${ANALYSIS_DIR}/scripts/diff_analysis.R << 'RSCRIPT'
library(DESeq2)
library(GenomicRanges)
library(Rsubread)

setwd(Sys.getenv("WORK_DIR"))

cat("=== Loading peaks ===\n")
samples <- unlist(strsplit(Sys.getenv("SAMPLES"), " "))
peak_files <- paste0("04_peaks/macs2/", samples, "_peaks.broadPeak")

peak_list <- list()
for(i in 1:length(samples)) {
  df <- read.table(peak_files[i], sep="\t")
  peak_list[[i]] <- GRanges(seqnames=df[,1], ranges=IRanges(start=df[,2], end=df[,3]))
  cat(sprintf("%s: %d peaks\n", samples[i], length(peak_list[[i]])))
}

cat("\n=== Merging peaks ===\n")
all_peaks <- do.call(c, peak_list)
consensus_peaks <- reduce(all_peaks)
cat(sprintf("Consensus: %d peaks\n", length(consensus_peaks)))

cat("\n=== Counting reads ===\n")
bam_files <- paste0("03_align/bam/", samples, ".final.bam")

saf <- data.frame(
  GeneID = paste0("peak_", 1:length(consensus_peaks)),
  Chr = as.character(seqnames(consensus_peaks)),
  Start = start(consensus_peaks),
  End = end(consensus_peaks),
  Strand = "."
)

fc <- featureCounts(files=bam_files, annot.ext=saf, isPairedEnd=TRUE, 
                    nthreads=as.numeric(Sys.getenv("THREADS")), 
                    requireBothEndsMapped=TRUE, countMultiMappingReads=FALSE)

count_matrix <- fc$counts
colnames(count_matrix) <- samples

cat("\n=== Running DESeq2 ===\n")
n_control <- as.numeric(Sys.getenv("N_CONTROL"))
n_treatment <- length(samples) - n_control

colData <- data.frame(
  condition = factor(c(rep("Control", n_control), rep("Treatment", n_treatment)), 
                     levels=c("Control", "Treatment")),
  row.names = samples
)

dds <- DESeqDataSetFromMatrix(countData=count_matrix, colData=colData, design=~condition)
dds <- dds[rowSums(counts(dds)) >= 10, ]
cat(sprintf("Filtered: %d peaks\n", nrow(dds)))

dds <- DESeq(dds)
res <- results(dds, contrast=c("condition", "Treatment", "Control"))

res_df <- as.data.frame(res)
res_df$peak_id <- rownames(res_df)
coords <- saf[match(res_df$peak_id, saf$GeneID), ]
res_df <- cbind(coords[,c("Chr","Start","End")], res_df)

write.table(res_df, "05_diff_analysis/all_peaks_deseq2_results.txt", 
            sep="\t", quote=F, row.names=F)

cat("\n=== Applying three thresholds ===\n")

# Standard: FDR<0.05, |log2FC|>1.0, baseMean>50
standard <- res_df[!is.na(res_df$padj) & res_df$padj<0.05 & 
                   abs(res_df$log2FoldChange)>1.0 & res_df$baseMean>50,]
standard_up <- standard[standard$log2FoldChange>0,]
standard_down <- standard[standard$log2FoldChange<0,]

# Loose: FDR<0.1, |log2FC|>0.585, baseMean>30
loose <- res_df[!is.na(res_df$padj) & res_df$padj<0.1 & 
                abs(res_df$log2FoldChange)>0.585 & res_df$baseMean>30,]
loose_up <- loose[loose$log2FoldChange>0,]
loose_down <- loose[loose$log2FoldChange<0,]

# Strict: FDR<0.01, |log2FC|>1.5, baseMean>100
strict <- res_df[!is.na(res_df$padj) & res_df$padj<0.01 & 
                 abs(res_df$log2FoldChange)>1.5 & res_df$baseMean>100,]
strict_up <- strict[strict$log2FoldChange>0,]
strict_down <- strict[strict$log2FoldChange<0,]

# Save results
write.table(standard, "05_diff_analysis/standard/diff_peaks_all.txt", sep="\t", quote=F, row.names=F)
write.table(standard_up, "05_diff_analysis/standard/diff_peaks_UP.txt", sep="\t", quote=F, row.names=F)
write.table(standard_down, "05_diff_analysis/standard/diff_peaks_DOWN.txt", sep="\t", quote=F, row.names=F)

write.table(loose, "05_diff_analysis/loose/diff_peaks_all.txt", sep="\t", quote=F, row.names=F)
write.table(loose_up, "05_diff_analysis/loose/diff_peaks_UP.txt", sep="\t", quote=F, row.names=F)
write.table(loose_down, "05_diff_analysis/loose/diff_peaks_DOWN.txt", sep="\t", quote=F, row.names=F)

write.table(strict, "05_diff_analysis/strict/diff_peaks_all.txt", sep="\t", quote=F, row.names=F)
write.table(strict_up, "05_diff_analysis/strict/diff_peaks_UP.txt", sep="\t", quote=F, row.names=F)
write.table(strict_down, "05_diff_analysis/strict/diff_peaks_DOWN.txt", sep="\t", quote=F, row.names=F)

cat("\n========================================\n")
cat("DIFFERENTIAL PEAK SUMMARY\n")
cat("========================================\n\n")

cat("Standard (FDR<0.05, |log2FC|>1.0, baseMean>50):\n")
cat(sprintf("  Total: %d | UP: %d | DOWN: %d\n\n", 
            nrow(standard), nrow(standard_up), nrow(standard_down)))

cat("Loose (FDR<0.1, |log2FC|>0.585, baseMean>30):\n")
cat(sprintf("  Total: %d | UP: %d | DOWN: %d\n\n", 
            nrow(loose), nrow(loose_up), nrow(loose_down)))

cat("Strict (FDR<0.01, |log2FC|>1.5, baseMean>100):\n")
cat(sprintf("  Total: %d | UP: %d | DOWN: %d\n\n", 
            nrow(strict), nrow(strict_up), nrow(strict_down)))

cat("=== DONE ===\n")
RSCRIPT

    # Run R script
    export WORK_DIR=${ANALYSIS_DIR}
    export SAMPLES="${SAMPLES[*]}"
    export THREADS=${PEAK_THREADS}
    export N_CONTROL=3  # Number of control samples
    
    Rscript ${ANALYSIS_DIR}/scripts/diff_analysis.R 2>&1 | tee ${ANALYSIS_DIR}/logs/diff/step5.log
    
    log_info "✓ Step 5 completed"
}

# ========== Main Pipeline ==========
main() {
    log_step "CUT&Tag Analysis Pipeline - H3K27ac"
    log_info "Start time: $(date)"
    
    check_software
    create_directories
    
    step1_qc
    step2_trim
    step3a_build_index
    step3b_align
    step4_peaks
    step5_diff_analysis
    
    log_step "Pipeline Completed Successfully!"
    log_info "End time: $(date)"
    
    echo ""
    echo -e "${GREEN}========================================${NC}"
    echo -e "${GREEN}     ANALYSIS COMPLETE!${NC}"
    echo -e "${GREEN}========================================${NC}"
    echo ""
    echo "Output Summary:"
    echo "  QC Reports: ${ANALYSIS_DIR}/01_fastqc/"
    echo "  Alignments: ${ANALYSIS_DIR}/03_align/bam/*.final.bam"
    echo "  Peaks: ${ANALYSIS_DIR}/04_peaks/macs2/*_peaks.broadPeak"
    echo "  Differential: ${ANALYSIS_DIR}/05_diff_analysis/"
    echo ""
}

# Run pipeline
main "$@"